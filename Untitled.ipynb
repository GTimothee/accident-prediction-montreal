{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather import *\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from os import mkdir\n",
    "from os.path import isdir, isfile\n",
    "from accidents_montreal import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql import Row\n",
    "import math\n",
    "from io import BytesIO, StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip fetching montreal accidents dataset: already downloaded\n",
      "Skip extraction of accidents montreal dataframe: already done, reading from file\n"
     ]
    }
   ],
   "source": [
    "fetch_accidents_montreal()\n",
    "spark = (SparkSession\n",
    "            .builder\n",
    "            .appName(\"Road accidents prediction\")\n",
    "            .getOrCreate())\n",
    "df=extract_accidents_montreal_dataframe(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=df.take(5)\n",
    "test = list(map(lambda e: (e.LOC_LAT, e.LOC_LONG), test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for t in test:\n",
    "    print(t)\n",
    "    lat, long = t\n",
    "    year, month, day = (2006,5,2)\n",
    "    hour = 0\n",
    "    stations = get_stations(lat, long, year, month, day)\n",
    "\n",
    "    weighted_average_num = 0\n",
    "    weighted_average_denum = 0\n",
    "    for station in stations:\n",
    "        identity=station[0]\n",
    "        cache_file_path = f'data/weather/s{identity}_{year}_{month}.h5'\n",
    "\n",
    "        \"\"\"if isfile(cache_file_path):\n",
    "            station_temp = (pd.read_hdf(cache_file_path, key='w')\n",
    "                    .loc[f'{year}-{month}-{day} {hour}:00'][0])\n",
    "        else:\"\"\"\n",
    "\n",
    "        url = (f'http://climate.weather.gc.ca/climate_data/bulk_data_e.html?'\n",
    "               f'format=csv&stationID={identity}&Year={year}&Month={month}&Day={day}&'\n",
    "               f'timeframe=1&submit=Download+Data')\n",
    "        csvfile = get(url).text\n",
    "        with StringIO(csvfile) as csvfile:\n",
    "            n_emptyLineMet = 0\n",
    "            while n_emptyLineMet < 2:\n",
    "                if csvfile.readline() == '\\n':\n",
    "                    n_emptyLineMet += 1\n",
    "\n",
    "            df = pd.read_csv(csvfile, usecols=['Date/Time', 'Temp (Â°C)'],\n",
    "                             index_col='Date/Time', parse_dates=['Date/Time'])\n",
    "\n",
    "        if not isdir('data/weather/'):\n",
    "            mkdir('data/weather/')\n",
    "        df.to_hdf(cache_file_path, key='w')\n",
    "        station_temp= df.loc[f'{year}-{month}-{day} {hour}:00'][0]\n",
    "\n",
    "        temp = station_temp   \n",
    "        if not math.isnan(temp):\n",
    "            weighted_average_num += temp / station[1]\n",
    "            weighted_average_denum += 1 / station[1]\n",
    "\n",
    "    res = weighted_average_num/weighted_average_denum\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AccidentsPredictionEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
