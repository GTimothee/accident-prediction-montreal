{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# credits: https://towardsdatascience.com/pyspark-and-xgboost-integration-tested-on-the-kaggle-titanic-dataset-4e75a568bdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import os\n",
    "import shutil\n",
    "from evaluate import *\n",
    "from random_forest import *\n",
    "from utils import init_spark\n",
    "from preprocess import get_positive_samples, \\\n",
    "                       get_negative_samples, \\\n",
    "                       get_dataset_df\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars data/xgboost4j-spark-0.72.jar,data/xgboost4j-0.72.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = init_spark()\n",
    "spark.sparkContext.addPyFile(\"data/sparkxgb.zip\")\n",
    "from sparkxgb import XGBoostEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "sample_ratio = 0.1\n",
    "neg_samples = get_negative_samples(spark).sample(sample_ratio).na.fill(0)\n",
    "pos_samples = get_positive_samples(spark).sample(sample_ratio).na.fill(0)\n",
    "df = get_dataset_df(spark, pos_samples, neg_samples).na.fill(0)\n",
    "trainDF, testDF = df.randomSplit([0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgboost = XGBoostEstimator(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "pipeline = Pipeline().setStages([xgboost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    workdir = \"./\"\n",
    "    path = \"data/xgboost.model\"\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(testDF) \n",
    "prediction = prediction.withColumn(\"rawPrediction\", prediction['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot graph\n",
    "\"\"\"area_under_PR, f1_score = evaluate_binary_classifier(prediction)\"\"\"\n",
    "\"\"\"pd_df = compute_precision_recall_graph(result_df, 20)\n",
    "pd_df.plot()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder().addGrid(xgboost.max_depth, [x for x in range(10, 50, 10)])\n",
    "                            .addGrid(xgboost.eta, [x for x in np.linspace(0.2, 0.6, 6)])\n",
    "                            .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\",\n",
    "                                      rawPredictionCol=\"probabilities\",\n",
    "                                      metricName=\"areaUnderPR\")\n",
    "\n",
    "cv = (CrossValidator()\n",
    "        .setEstimator(pipeline)\n",
    "        .setEvaluator(evaluator)\n",
    "        .setEstimatorParamMaps(paramGrid)\n",
    "        .setNumFolds(3))\n",
    "\n",
    "cvModel = cv.fit(trainDF)\n",
    "\n",
    "bestModel = (cvModel.bestModel\n",
    "                    .asInstanceOf[PipelineModel]\n",
    "                    .stages(2)\n",
    "                    .asInstanceOf[XGBoostClassificationModel])\n",
    "\n",
    "bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AccidentsPredictionEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
