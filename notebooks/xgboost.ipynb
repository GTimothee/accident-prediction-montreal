{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# credits: https://towardsdatascience.com/pyspark-and-xgboost-integration-tested-on-the-kaggle-titanic-dataset-4e75a568bdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/workspace/projects/accident-prediction-montreal\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import os\n",
    "import shutil\n",
    "from evaluate import *\n",
    "from random_forest import *\n",
    "from utils import init_spark\n",
    "from preprocess import get_positive_samples, \\\n",
    "                       get_negative_samples, \\\n",
    "                       get_dataset_df\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars data/xgboost4j-spark-0.72.jar,data/xgboost4j-0.72.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session created\n",
      "Parameters:\n",
      "\tspark.jars: file:///home/user/Documents/workspace/projects/accident-prediction-montreal/data/xgboost4j-spark-0.72.jar,file:///home/user/Documents/workspace/projects/accident-prediction-montreal/data/xgboost4j-0.72.jar\n",
      "\tspark.executor.id: driver\n",
      "\tspark.driver.port: 42495\n",
      "\tspark.driver.host: 192.168.100.49\n",
      "\tspark.app.name: Accident prediction\n",
      "\tspark.serializer: org.apache.spark.serializer.KryoSerializer\n",
      "\tspark.repl.local.jars: file:///home/user/Documents/workspace/projects/accident-prediction-montreal/data/xgboost4j-spark-0.72.jar,file:///home/user/Documents/workspace/projects/accident-prediction-montreal/data/xgboost4j-0.72.jar\n",
      "\tspark.driver.memory: 3g\n",
      "\tspark.rdd.compress: True\n",
      "\tspark.app.id: local-1555304588938\n",
      "\tspark.serializer.objectStreamReset: 100\n",
      "\tspark.master: local[*]\n",
      "\tspark.submit.deployMode: client\n",
      "\tspark.ui.showConsoleProgress: true\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "spark.sparkContext.addPyFile(\"data/sparkxgb.zip\")\n",
    "from sparkxgb import XGBoostEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "sample_ratio = 0.1\n",
    "neg_samples = get_negative_samples(spark).sample(sample_ratio).na.fill(0)\n",
    "pos_samples = get_positive_samples(spark).sample(sample_ratio).na.fill(0)\n",
    "df = get_dataset_df(spark, pos_samples, neg_samples).na.fill(0)\n",
    "trainDF, testDF = df.randomSplit([0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgboost = XGBoostEstimator(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "pipeline = Pipeline().setStages([xgboost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    workdir = \"./\"\n",
    "    path = \"data/xgboost.model\"\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(testDF) \n",
    "prediction = prediction.withColumn(\"rawPrediction\", prediction['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot graph\n",
    "\"\"\"area_under_PR, f1_score = evaluate_binary_classifier(prediction)\"\"\"\n",
    "\"\"\"pd_df = compute_precision_recall_graph(result_df, 20)\n",
    "pd_df.plot()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder().addGrid(xgboost.max_depth, [x for x in range(3, 20, 6)])\n",
    "                            .addGrid(xgboost.eta, [x for x in np.linspace(0.2, 0.6, 4)])\n",
    "                            .addGrid(xgboost.scale_pos_weight, [x for x in np.linspace(0.03, 1.0, 12)])\n",
    "                             .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\",\n",
    "                                      rawPredictionCol=\"probabilities\",\n",
    "                                      metricName=\"areaUnderPR\")\n",
    "\n",
    "cv = (CrossValidator()\n",
    "        .setEstimator(pipeline)\n",
    "        .setEvaluator(evaluator)\n",
    "        .setEstimatorParamMaps(paramGrid)\n",
    "        .setNumFolds(3))\n",
    "\n",
    "cvModel = cv.fit(trainDF)\n",
    "\n",
    "bestModel = (cvModel.bestModel\n",
    "                    .asInstanceOf[PipelineModel]\n",
    "                    .stages(2)\n",
    "                    .asInstanceOf[XGBoostClassificationModel])\n",
    "\n",
    "bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AccidentsPredictionEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
