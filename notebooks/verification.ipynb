{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/workspace/projects/accident-prediction-montreal\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accidents_montreal import fetch_accidents_montreal,\\\n",
    "                               extract_accidents_montreal_df,\\\n",
    "                               get_accident_df\n",
    "from road_network import distance_intermediate_formula,\\\n",
    "                         distance_measure,\\\n",
    "                         get_road_features_df,\\\n",
    "                         get_road_df\n",
    "from weather import add_weather_columns, extract_year_month_day\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import row_number, col, rank, avg, split, to_date, \\\n",
    "                                  rand, monotonically_increasing_id\n",
    "from os.path import isdir\n",
    "from shutil import rmtree\n",
    "import datetime\n",
    "from preprocess import generate_dates_df, init_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip fetching road network: already downloaded\n",
      "Extracting road network dataframe...\n",
      "Extracting road network dataframe done\n",
      "Skip extracting road features: already done\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "cache_path = 'data/negative-samples.parquet'\n",
    "if isdir(cache_path):\n",
    "    try:\n",
    "        print(\"test\")\n",
    "        #return spark.read.parquet(cache_path)\n",
    "    except Exception:\n",
    "        print('Failed reading from disk cache')\n",
    "        rmtree(cache_path)\n",
    "\n",
    "dates_df = generate_dates_df(\"01/01/2012\", \"01/01/2017\", spark).limit(20)\n",
    "road_df = get_road_df(spark).limit(20)\n",
    "road_features_df = get_road_features_df(spark, road_df=road_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['street_name',\n",
       " 'street_type',\n",
       " 'center_long',\n",
       " 'center_lat',\n",
       " 'coord_long',\n",
       " 'coord_lat',\n",
       " 'street_id']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_df = (road_df.select(['center_long', 'center_lat', 'street_id'])\n",
    "                  .withColumnRenamed('center_lat', 'loc_lat')\n",
    "                  .withColumnRenamed('center_long', 'loc_long')\n",
    "                  .orderBy(rand())\n",
    "                  .persist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = (dates_df.rdd\n",
    "                            .cartesian(road_df.rdd)\n",
    "                            .map(lambda row: row[0] + row[1])\n",
    "                            .toDF(['date', 'hour', 'loc_long',\n",
    "                                   'loc_lat', 'street_id'])\n",
    "                            .withColumn('accident_id',\n",
    "                                        monotonically_increasing_id())\n",
    "                            .persist())\n",
    "\n",
    "negative_samples = (add_weather_columns(spark, negative_samples)\n",
    "                    .join(road_features_df, 'street_id'))\n",
    "\n",
    "negative_samples.write.parquet(cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AccidentsPredictionEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
