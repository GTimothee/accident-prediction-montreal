{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather import *\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from os import mkdir\n",
    "from os.path import isdir, isfile\n",
    "from accidents_montreal import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql import Row\n",
    "import math\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New for testing weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old for development and experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= test[0]\n",
    "lat, long = t\n",
    "year, month, day = (2006,5,2)\n",
    "hour = 0\n",
    "stations = get_stations(lat, long, year, month, day)\n",
    "weighted_average_num = 0\n",
    "weighted_average_denum = 0\n",
    "weathers = list()\n",
    "cols=list()\n",
    "for station in stations:\n",
    "    identity=station[0]\n",
    "    cache_file_path = f'data/weather/s{identity}_{year}_{month}.h5'\n",
    "    if isfile(cache_file_path):\n",
    "        df = pd.read_hdf(cache_file_path, key='w')\n",
    "    else:\n",
    "        url = (f'http://climate.weather.gc.ca/climate_data/bulk_data_e.html?'\n",
    "               f'format=csv&stationID={identity}&Year={year}&Month={month}&Day={day}&'\n",
    "               f'timeframe=1&submit=Download+Data')\n",
    "        print(url)\n",
    "        csvfile = get(url).text\n",
    "        with StringIO(csvfile) as csvfile:\n",
    "            skip_header(csvfile)\n",
    "\n",
    "            df = pd.read_csv(csvfile,\n",
    "                             index_col='Date/Time', parse_dates=['Date/Time'])\n",
    "\n",
    "        if not isdir('data/weather/'):\n",
    "            mkdir('data/weather/')\n",
    "        df.to_hdf(cache_file_path, key='w')\n",
    "    \n",
    "    s=df.loc[f'{year}-{month}-{day} {hour}:00'] \n",
    "    s.loc[\"station_denom\"] = station[1]\n",
    "    \"\"\"s['Temp (째C)'] = s.at['Temp (째C)']/station[1]\n",
    "    print(s['Temp (째C)'])\"\"\"\n",
    "    if len(cols) == 0:\n",
    "        cols = df.columns.values.tolist() + [\"station_denom\"]\n",
    "    weathers.append(s)\n",
    "\n",
    "weathers = pd.DataFrame(weathers, columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temperatures = weathers[['Temp (째C)', 'station_denom']] \\\n",
    "    .dropna() \\\n",
    "    .apply(lambda row: pd.Series([row[0]/row[1], 1/row[1]]), axis=1) \n",
    "temperatures[0].sum() / temperatures[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols=[col for col in list(wheathers.dtypes.index) if wheathers.dtypes[col] in ['int64','float64']]\n",
    "non_numeric_cols = [col for col in list(wheathers.dtypes.index) if col not in numeric_cols+['Weather']]\n",
    "numeric_wheathers = wheathers.loc[:,numeric_cols]\n",
    "means = numeric_wheathers.mean()\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_num_wheathers = wheathers.loc[:,non_numeric_cols] \n",
    "weather = wheathers.loc[:,'Weather'].dropna().drop_duplicates().values.tolist()\n",
    "non_num_wheathers.iat[5,2]='A'\n",
    "\n",
    "def get_majority_vote(col):\n",
    "    vals = col.dropna().drop_duplicates().tolist()\n",
    "    if len(vals) > 0:\n",
    "        e= max(set(vals), key=vals.count)\n",
    "        return [v for v in vals if vals.count(e)==vals.count(v)]\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "non_num_wheathers = non_num_wheathers.apply(lambda col:small_func(col), axis=0)\n",
    "a=non_num_wheathers.index.values.tolist()\n",
    "b=non_num_wheathers.values.tolist()\n",
    "c=means.index.values.tolist()\n",
    "d=means.values.tolist()\n",
    "indexes = a + c + ['Weather']\n",
    "vals = b + d + [weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Row(**dict(zip(indexes, vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AccidentsPredictionEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
